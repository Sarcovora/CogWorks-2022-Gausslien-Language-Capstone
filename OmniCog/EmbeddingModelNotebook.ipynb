{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe9eb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import mygrad as mg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41acfa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cogworks_data.language import get_data_path\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# load COCO metadata\n",
    "filename = get_data_path(\"captions_train2014.json\")\n",
    "with Path(filename).open() as f:\n",
    "    coco_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a97bb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with Path(get_data_path('resnet18_features.pkl')).open('rb') as f:\n",
    "    resnet18_features = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fcafe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports which aren't yet here because I'm lazy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6180be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mynn.layers.dense import dense\n",
    "from mygrad.nnet.initializers import glorot_normal\n",
    "import numpy as np\n",
    "\n",
    "class Model():\n",
    "    \"\"\"\n",
    "    Model that creates semantic space embeddings using the original image vectors\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, output_dim, stored_weights=None):\n",
    "        \"\"\" \n",
    "        Initializes the layer\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        dim_input: int \n",
    "            The original image descriptor vector dimension\n",
    "        \n",
    "        dim_output: int\n",
    "            The final image embedding dimension\n",
    "        \"\"\"\n",
    "        self.dense_layer = dense(input_dim, output_dim, weight_initializer=glorot_normal, bias=False)\n",
    "        if stored_weights is not None:\n",
    "            self.dense_layer.weight = mg.astensor(stored_weights)\n",
    "    def __call__(self, x):\n",
    "        \"\"\"\n",
    "        Does one forward pass of the network\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x: Union[numpy.ndarray, mygrad.Tensor], shape=(training data length, input_dim)\n",
    "            The training data of image descriptor vectors\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        mygrad.Tensor, shape=(training data length, output_dim)\n",
    "            The normalized image embeddings predicted by the model\n",
    "        \"\"\"\n",
    "        embeddings = self.dense_layer(x)\n",
    "        magnitude = np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "        \n",
    "        return embeddings / magnitude\n",
    "        \n",
    "    @property\n",
    "    def parameters(self):\n",
    "        \"\"\"\n",
    "        Gets the model's parameters\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[Tensor, ...]\n",
    "            The weights of the model\n",
    "        \"\"\"\n",
    "        return self.dense_layer.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4314390f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weights():\n",
    "    \"\"\" \n",
    "        Loads the weights from the numpy array file\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        The array of weights\n",
    "        \"\"\"\n",
    "    return np.load('WeightsArray.npy')\n",
    "\n",
    "def save_weights(arr: np.array):\n",
    "    \"\"\" \n",
    "        Stores the weights to the numpy array file\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        arr: np.array\n",
    "            The array of weights\n",
    "        \"\"\"\n",
    "    np.save('WeightsArray.npy', arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7feb7214",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from noggin import create_plot\n",
    "plotter, fig, ax = create_plot(metrics=[\"loss\", \"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3930b32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mynn.optimizers.sgd import SGD\n",
    "from OmniCog import CocoDataManager, train_split, extract_triples\n",
    "# from OmniCog import margin_loss\n",
    "from embed_query import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5b12f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def margin_loss(trueVec, captionVec, confuserVec, margin=0.25):\n",
    "    truesim = np.einsum(\"nd,nd->n\", trueVec, captionVec)\n",
    "    confusesim = np.einsum(\"nd,nd->n\", confuserVec, captionVec)\n",
    "    return margin_ranking_loss(truesim, confusesim, margin=margin, y=1), truesim, confusesim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f66311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only run if we actually stored weights to use, need this cell for testing\n",
    "model2 = Model(512, 200, load_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73921fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = CocoDataManager(coco_data, resnet18_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37838ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(512, 200)\n",
    "optimizer = SGD(model.parameters, learning_rate = 1e-3, momentum=0.9)\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "testing, training = train_split(manager.imageIDs, validation=0.2)\n",
    "print(len(training), len(testing))\n",
    "print(len(training)/batch_size)\n",
    "\n",
    "for iteration in range(0, epochs):\n",
    "    training_data = extract_triples(manager, training, validation=True)\n",
    "#     print(type(training_data))\n",
    "#     print(training_data)\n",
    "    # creates a shuffled array of training indices\n",
    "    indices = np.arange(len(training_data))\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    # trains the model by improving the loss and accuracy metrics for the training data in batches\n",
    "    for batch_count in range(0, len(training_data)//batch_size):\n",
    "#     for batch_count in np.zeros(len(training_data)//batch_size):\n",
    "        batch_indices = indices[batch_count * batch_size : (batch_count+1) * batch_size]\n",
    "#         batch_indices = indices[0 : 32]\n",
    "        batch = training_data[batch_indices]\n",
    "        \n",
    "        true_x = np.array([normalize(resnet18_features[true_vec][0]) for (true_vec, _, _) in batch])\n",
    "        conf_x = np.array([normalize(resnet18_features[confuse_vec][0]) for (_, _, confuse_vec) in batch])\n",
    "        \n",
    "#         print(true_x)\n",
    "#         print(conf_x)\n",
    "        \n",
    "        true_embedding = model(true_x)\n",
    "        confuser_embedding = model(conf_x)\n",
    "        \n",
    "        caption_embedding = [manager.captionID_to_captionEmbedding[captionid] for (_, captionid, _) in batch]\n",
    "        caption_embedding = np.array(caption_embedding)\n",
    "        \n",
    "        print(true_embedding)\n",
    "        print(confuser_embedding)\n",
    "        print(caption_embedding)\n",
    "        \n",
    "        loss, truesim, confusesim = margin_loss(true_embedding, caption_embedding, confuser_embedding)\n",
    "        accuracy = (truesim > (confusesim + 0.25)).mean()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        plotter.set_train_batch({\"loss\":loss.item(), \"accuracy\":accuracy}, batch_size=batch_size, plot=True)\n",
    "    # creates a shuffled array of training indices  \n",
    "    testing_data = extract_triples(manager, testing, validation=True)\n",
    "    test_indices = np.arange(len(testing_data))\n",
    "    np.random.shuffle(test_indices)\n",
    "    \n",
    "    with mg.no_autodiff:\n",
    "        # calculates the loss and accuracy for the validation data in batches\n",
    "        for batch_count in range(0, len(testing_data)//batch_size):\n",
    "            test_batch_indices = test_indices[batch_count * batch_size : (batch_count+1) * batch_size]\n",
    "            test_batch = testing_data[test_batch_indices]\n",
    "\n",
    "            true_x = np.array([resnet18_features[true_vec][0] for (true_vec, _, _) in test_batch])\n",
    "            conf_x = np.array([resnet18_features[confuse_vec][0] for (_, _, confuse_vec) in test_batch])\n",
    "\n",
    "            true_embedding = model(true_x)\n",
    "            confuser_embedding = model(conf_x)\n",
    "\n",
    "            caption_embedding = [manager.captionID_to_captionEmbedding[captionid] for (_, captionid, _) in test_batch]\n",
    "            caption_embedding = np.array(caption_embedding)\n",
    "\n",
    "#             test_loss = margin_loss(true_embedding, caption_embedding, confuser_embedding)\n",
    "#             test_accuracy = batch_accuracy(loss)\n",
    "#             test_avg_loss = np.mean(loss)\n",
    "            test_loss, test_truesim, test_confusesim = margin_loss(true_embedding, caption_embedding, confuser_embedding)\n",
    "            test_accuracy = (test_truesim > (test_confusesim + 0.25)).mean()\n",
    "\n",
    "            plotter.set_test_batch({\"loss\":test_loss.item(), \"accuracy\":test_accuracy}, batch_size=batch_size)\n",
    "    \n",
    "    # plots the loss and accuracy in each epoch\n",
    "#     print(iteration)\n",
    "    plotter.set_train_epoch()\n",
    "    plotter.set_test_epoch()\n",
    "\n",
    "# stores the final weights in a file\n",
    "save_weights(model.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0408b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[228409 801529 232338]\n",
    "[228409 801637 433683]\n",
    "[228409 805120 122235]\n",
    "'''\n",
    "img_id = 228409\n",
    "caption_id = 801529\n",
    "confuzlation_id = 232338\n",
    "url = manager.getUrl(img_id)\n",
    "confuzled_url = manager.getUrl(confuzlation_id)\n",
    "caption = manager.captionID_to_caption[caption_id]\n",
    "print(url, '\\n', caption, '\\n', confuzled_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbd7c78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
